GOOGLE_MODELS = {
    #   .oooooo.                                   oooo                  .o.       ooooo
    #  d8P'  `Y8b                                  `888                 .888.      `888'
    # 888            .ooooo.   .ooooo.   .oooooooo  888   .ooooo.      .8"888.      888
    # 888           d88' `88b d88' `88b 888' `88b   888  d88' `88b    .8' `888.     888
    # 888     ooooo 888   888 888   888 888   888   888  888ooo888   .88ooo8888.    888
    # `88.    .88'  888   888 888   888 `88bod8P'   888  888    .o  .8'     `888.   888
    #  `Y8bood8P'   `Y8bod8P' `Y8bod8P' `8oooooo.  o888o `Y8bod8P' o88o     o8888o o888o
    #                                   d"     YD
    #                                   "Y88888P'
    # these are through AI studio rather than Vertex, and using the OpenAI-compatible endpoints
    "gemini-2.0-flash-compat": {
        "id": "gemini-2.0-flash-compat",
        "name": "gemini-2.0-flash",
        "api_base": "https://generativelanguage.googleapis.com/v1beta/openai",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "openai",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": False,
    },
    "gemini-2.0-flash-lite-compat": {
        "id": "gemini-2.0-flash-lite-compat",
        "name": "gemini-2.0-flash-lite",
        "api_base": "https://generativelanguage.googleapis.com/v1beta/openai",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "openai",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": False,
    },
    "gemini-2.5-pro-compat": {
        "id": "gemini-2.5-pro-compat",
        "name": "gemini-2.5-pro",
        "api_base": "https://generativelanguage.googleapis.com/v1beta/openai",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "openai",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": True,
    },
    "gemini-2.5-flash-compat": {
        "id": "gemini-2.5-flash-compat",
        "name": "gemini-2.5-flash",
        "api_base": "https://generativelanguage.googleapis.com/v1beta/openai",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "openai",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": True,
    },
    "gemini-2.5-flash-lite-compat": {
        "id": "gemini-2.5-flash-lite-compat",
        "name": "gemini-2.5-flash-lite",
        "api_base": "https://generativelanguage.googleapis.com/v1beta/openai",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "openai",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": True,
    },
    # Native Gemini API versions with file support
    "gemini-2.0-flash": {
        "id": "gemini-2.0-flash",
        "name": "gemini-2.0-flash",
        "api_base": "https://generativelanguage.googleapis.com/v1beta",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "gemini",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": False,
    },
    "gemini-2.0-flash-lite": {
        "id": "gemini-2.0-flash-lite",
        "name": "gemini-2.0-flash-lite",
        "api_base": "https://generativelanguage.googleapis.com/v1beta",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "gemini",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": False,
    },
    "gemini-2.5-pro": {
        "id": "gemini-2.5-pro",
        "name": "gemini-2.5-pro",
        "api_base": "https://generativelanguage.googleapis.com/v1beta",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "gemini",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": True,
    },
    "gemini-2.5-flash": {
        "id": "gemini-2.5-flash",
        "name": "gemini-2.5-flash",
        "api_base": "https://generativelanguage.googleapis.com/v1beta",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "gemini",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": True,
    },
    "gemini-2.5-flash-lite": {
        "id": "gemini-2.5-flash-lite",
        "name": "gemini-2.5-flash-lite",
        "api_base": "https://generativelanguage.googleapis.com/v1beta",
        "api_key_env_var": "GEMINI_API_KEY",
        "supports_json": True,
        "supports_logprobs": False,
        "api_spec": "gemini",
        "input_cost": 0.1,
        "output_cost": 0.4,
        "requests_per_minute": 20,
        "tokens_per_minute": 100_000,
        "reasoning_model": True,
    },
}
