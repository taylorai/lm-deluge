META_MODELS = {
    # `7MMM.     ,MMF'         mm
    #   MMMb    dPMM           MM
    #   M YM   ,M MM  .gP"Ya mmMMmm  ,6"Yb.
    #   M  Mb  M' MM ,M'   Yb  MM   8)   MM
    #   M  YM.P'  MM 8M""""""  MM    ,pm9MM
    #   M  `YM'   MM YM.    ,  MM   8M   MM
    # .JML. `'  .JMML.`Mbmmd'  `Mbmo`Moo9^Yo.
    "llama-4-scout": {
        "id": "llama-4-scout",
        "name": "Llama-4-Scout-17B-16E-Instruct-FP8",
        "api_base": "https://api.llama.com/compat/v1",
        "api_key_env_var": "META_API_KEY",
        "supports_json": True,
        "supports_logprobs": True,
        "api_spec": "openai",
        "input_cost": 0.0,
        "output_cost": 0.0,
        "requests_per_minute": 3_000,
        "tokens_per_minute": 1_000_000,
        "reasoning_model": False,
    },
    "llama-4-maverick": {
        "id": "llama-4-maverick",
        "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
        "api_base": "https://api.llama.com/compat/v1",
        "api_key_env_var": "META_API_KEY",
        "supports_json": True,
        "supports_logprobs": True,
        "api_spec": "openai",
        "input_cost": 0.0,
        "output_cost": 0.0,
        "requests_per_minute": 3_000,
        "tokens_per_minute": 1_000_000,
        "reasoning_model": False,
    },
    "llama-3.3-70b": {
        "id": "llama-3.3-70b",
        "name": "Llama-3.3-70B-Instruct",
        "api_base": "https://api.llama.com/compat/v1",
        "api_key_env_var": "META_API_KEY",
        "supports_json": True,
        "supports_logprobs": True,
        "api_spec": "openai",
        "input_cost": 0.0,
        "output_cost": 0.0,
        "requests_per_minute": 3_000,
        "tokens_per_minute": 1_000_000,
        "reasoning_model": False,
    },
    "llama-3.3-8b": {
        "id": "llama-3.3-8b",
        "name": "Llama-3.3-8B-Instruct",
        "api_base": "https://api.llama.com/compat/v1",
        "api_key_env_var": "META_API_KEY",
        "supports_json": True,
        "supports_logprobs": True,
        "api_spec": "openai",
        "input_cost": 0.0,
        "output_cost": 0.0,
        "requests_per_minute": 3_000,
        "tokens_per_minute": 1_000_000,
        "reasoning_model": False,
    },
}
